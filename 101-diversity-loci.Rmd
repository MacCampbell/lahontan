---
title: "101-diversity-loci"
output: html_document
date: "2023-08-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r}
library(tidyverse)
```

     
Samples

_norm - normalized for sample sizes between basins 100-130

filtered - filtered based on 'populations' hybridization results in contract (low read counts, potential hybrids, removed)
norm- then reduced sample sizes for each 'population' to be more consistent across populations    

LCT_norm.bamlist   467 samples -> distributed across Truckee, Walker, Carson 

Diversity loci for each location with thetas.     
Walker, Carson, Truckee, Independence Lake, Heenan Lake (use Heenan Lake fish with better sample sizes)          

There are several   

_1_ We have Walker, Carson, Truckee, Independence Lake from 2016 and Heenan Lake from 2016     
_2_ Should examine readcounts/average coverage across all samples in these bamlists
_3_ Identify top_n samples from each group Walker -> Mix up , Carson -> Mix up , Truckee- Mix up, separate Independence Lake and Heenan Lake   
_4_ Call SNPs and filter for HWE/Missingness/MAF > 0.1-0.4
_5_ Do PCA for funsies
_6_ Theta/Tajima's D for larger groups (from called SNPs)    

Macklin Does not go in Truckee because it is in the Yuba
Do not include Oharell

```{r}
meta<-read_csv("meta/LCT_norm_meta-08092023.csv")
meta
```

```{r}
bamlist<-read_tsv(file="bamlists/LCT_norm.bamlist", col_names = c("Path"))
bamlist$SampleID<-gsub(".sort.flt.bam","",bamlist$Path)
bamlist$SampleID<-gsub("/home.+/","",bamlist$SampleID)
bamlist<-bamlist %>% select(SampleID, Path)
bamlist
```

```{r}
m2<-meta %>% left_join(bamlist) %>% mutate(NewPath=paste0("bams",SampleID,".sort.flt.bam"))
m2 %>% group_by(Species_code, Group, Creek) %>% summarize(Count=n())
write_csv(m2, file="meta/lct-norm-with-path.csv")
```

note mismatch with Byday samples at line 295, editing those 

Ok, so we don't know the coverage of these samples.    

`(base) maccamp@farm:~/lahontan/bams$ ls | grep sort.flt.bam | perl -pe 's/.sort.flt.bam//g' > sample-list.txt`

`../101.1-do-counts.sh sample-list.txt`     

Read in coverage.    

```{r}
files<-list.files(path="outputs/101", patter="*.stats", full.names = TRUE)
reads<-lapply(files, read.csv, header=FALSE, col.names=c("SampleID","Aligned","Filtered","Coverage"))
reads<-bind_rows(reads)
```

```{r}
m2<-left_join(meta, reads)
```

```{r}
ggplot(m2) +
  geom_histogram(aes(x=Filtered, fill=Group)) +
  scale_fill_viridis_d(option="turbo") +
  theme_bw() +
  ylab("Count") +
  xlab("Filtered Read Number") +
  theme(panel.grid=element_blank())

min(m2$Filtered)
mean(m2$Filtered)
median(m2$Filtered)
max(m2$Filtered)
```



## Get some things we want

Walker, Carson, Truckee, Independence Lake, Heenan Lake (use Heenan Lake fish with better sample sizes)          
Independence lake fish all from 2010
```{r}
w<-m2 %>% filter(Group=="WALK")
wsub<-w %>% mutate(Diff=abs(Filtered-median(m2$Filtered))) %>% top_n(20,-Diff)

c<-m2 %>% filter(watershedCode=="CAR")
csub<-c %>% mutate(Diff=abs(Filtered-median(m2$Filtered))) %>% top_n(20,-Diff)

t<-m2 %>% filter(watershedCode=="TKR")
tsub<-t %>% mutate(Diff=abs(Filtered-median(m2$Filtered))) %>% top_n(20,-Diff)

i<-m2 %>% filter(watershedCode=="IPL")
isub<-i %>% mutate(Diff=abs(Filtered-median(m2$Filtered))) %>% top_n(20,-Diff)

h<-m2 %>% filter(watershedCode=="CAR_HL") 
hsub<-h %>% mutate(Diff=abs(Filtered-median(m2$Filtered))) %>% top_n(20,-Diff)

sub<-bind_rows(wsub, csub, tsub, isub, hsub)

```

This gives use 100 fish

```{r}

ggplot(sub) +
  geom_histogram(aes(x=Filtered, fill=Group)) +
  scale_fill_viridis_d(option="turbo") +
  theme_bw() +
  ylab("Count") +
  xlab("Filtered Read Number") +
  theme(panel.grid=element_blank())
```


Let's do some sanity checks by doing some genotype calls on Chrom01 and looking at a PCA

```